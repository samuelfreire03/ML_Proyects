{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook de Deep Learning: Clasificación de Jugadores de Fútbol\n",
    "\n",
    "This notebook is used for performing exploratory data analysis on the raw data. The goal is to understand the data better, visualize distributions, and identify patterns or anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Carga y Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_football_dataset(csv_path, image_dir):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        img_path = os.path.join(image_dir, row['image_name'])\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = img.resize((224, 224))\n",
    "            img_array = np.array(img) / 255.0\n",
    "            images.append(img_array)\n",
    "            labels.append(row['position'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "csv_path = 'football_players.csv'\n",
    "image_dir = 'player_images'\n",
    "X, y = load_football_dataset(csv_path, image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X, y_categorical, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Análisis Exploratorio de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x=y)\n",
    "plt.title('Distribución de Posiciones de Jugadores')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.title(le.inverse_transform([y_train[i]])[0])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Modelos Tradicionales (Features Extraídos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        hist = cv2.calcHist([gray], [0], None, [256], [0, 256]).flatten()\n",
    "        hog = cv2.HOGDescriptor((64,64), (16,16), (8,8), (8,8), 9).compute(gray)\n",
    "        features.append(np.concatenate([hist, hog.flatten()]))\n",
    "    return np.array(features)\n",
    "\n",
    "X_train_features = extract_features(X_train)\n",
    "X_test_features = extract_features(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_test_scaled = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=le.classes_))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "\n",
    "print(\"SVM Results:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=le.classes_))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimators=300, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test_scaled)\n",
    "\n",
    "print(\"XGBoost Results:\")\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=le.classes_))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Modelos de Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 CNN Básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(le.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history_cnn = cnn_model.fit(X_train, y_train,\n",
    "                            epochs=30,\n",
    "                            batch_size=32,\n",
    "                            validation_split=0.2,\n",
    "                            callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_cnn.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_cnn.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('CNN Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_cnn.history['loss'], label='Train Loss')\n",
    "plt.plot(history_cnn.history['val_loss'], label='Validation Loss')\n",
    "plt.title('CNN Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 CNN con Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "cnn_aug_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(le.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_aug_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "history_aug = cnn_aug_model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    epochs=50,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(factor=0.1, patience=5)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Transfer Learning con VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "vgg_model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(le.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "vgg_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history_vgg = vgg_model.fit(\n",
    "    datagen.flow(X_train_cnn, y_train_cnn, batch_size=32),\n",
    "    epochs=30,\n",
    "    validation_data=(X_test_cnn, y_test_cnn),\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(factor=0.2, patience=3)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Evaluación Comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, is_cnn=False):\n",
    "    if is_cnn:\n",
    "        y_pred = np.argmax(model.predict(X), axis=1)\n",
    "        y_true = np.argmax(y, axis=1)\n",
    "    else:\n",
    "        y_pred = model.predict(X)\n",
    "        y_true = y\n",
    "    print(classification_report(y_true, y_pred, target_names=le.classes_))\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title('Matriz de Confusión')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Verdadero')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluación CNN Básica:\")\n",
    "evaluate_model(cnn_model, X_test, y_test)\n",
    "\n",
    "print(\"\\nEvaluación CNN con Data Augmentation:\")\n",
    "evaluate_model(cnn_aug_model, X_test, y_test)\n",
    "\n",
    "print(\"\\nEvaluación VGG16 Transfer Learning:\")\n",
    "evaluate_model(vgg_model, X_test_cnn, y_test_cnn, is_cnn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Visualización de Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(12):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    img = X_test[i]\n",
    "    true_label = le.inverse_transform([y_test[i]])[0]\n",
    "    \n",
    "    cnn_pred = np.argmax(cnn_model.predict(img[np.newaxis, ...]))\n",
    "    cnn_label = le.inverse_transform([cnn_pred])[0]\n",
    "    \n",
    "    vgg_pred = np.argmax(vgg_model.predict(img[np.newaxis, ...]))\n",
    "    vgg_label = le.inverse_transform([vgg_pred])[0]\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"True: {true_label}\\nCNN: {cnn_label}\\nVGG: {vgg_label}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Métricas Comparativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Random Forest': rf,\n",
    "    'SVM': svm,\n",
    "    'XGBoost': xgb,\n",
    "    'CNN Básica': cnn_model,\n",
    "    'CNN Aug': cnn_aug_model,\n",
    "    'VGG16': vgg_model\n",
    "}\n",
    "\n",
    "accuracies = []\n",
    "for name, model in models.items():\n",
    "    if name in ['CNN Básica', 'CNN Aug']:\n",
    "        y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "    elif name == 'VGG16':\n",
    "        y_pred = np.argmax(model.predict(X_test_cnn), axis=1)\n",
    "        acc = accuracy_score(np.argmax(y_test_cnn, axis=1), y_pred)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=list(models.keys()), y=accuracies)\n",
    "plt.title('Comparación de Accuracy entre Modelos')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Análisis de Errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_vgg = np.argmax(vgg_model.predict(X_test_cnn), axis=1)\n",
    "y_true_vgg = np.argmax(y_test_cnn, axis=1)\n",
    "errors = np.where(y_pred_vgg != y_true_vgg)[0]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, idx in enumerate(errors[:12]):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    img = X_test[idx]\n",
    "    true_label = le.inverse_transform([y_true_vgg[idx]])[0]\n",
    "    pred_label = le.inverse_transform([y_pred_vgg[idx]])[0]\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Fine-Tuning del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "vgg_model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history_finetune = vgg_model.fit(\n",
    "    datagen.flow(X_train_cnn, y_train_cnn, batch_size=32),\n",
    "    epochs=20,\n",
    "    validation_data=(X_test_cnn, y_test_cnn),\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(factor=0.1, patience=3)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluación VGG16 después de Fine-Tuning:\")\n",
    "evaluate_model(vgg_model, X_test_cnn, y_test_cnn, is_cnn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Guardar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.save('football_player_classifier_vgg16.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Carga y Prueba del Modelo Guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('football_player_classifier_vgg16.h5')\n",
    "\n",
    "test_img_path = 'test_player.jpg'\n",
    "test_img = Image.open(test_img_path).convert('RGB')\n",
    "test_img = test_img.resize((224, 224))\n",
    "test_img_array = np.array(test_img) / 255.0\n",
    "\n",
    "prediction = loaded_model.predict(test_img_array[np.newaxis, ...])\n",
    "predicted_class = np.argmax(prediction)\n",
    "predicted_label = le.inverse_transform([predicted_class])[0]\n",
    "\n",
    "plt.imshow(test_img)\n",
    "plt.title(f\"Predicted Position: {predicted_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
